[general]
TAG: :dev


[logs]
# global configs for all of abaco
#level = ERROR
level = DEBUG

# configs for specific modules
level.worker = DEBUG
level.docker_utils = DEBUG
#level.spawner = DEBUG
#level.controllers = DEBUG


[store]
# url for the mongo instance
mongo_host: 172.17.0.1

# port for the mongo instance
mongo_port: 27017

# uncomment the next two lines for authenticated mongo
#mongo_user: abaco
#mongo_password: the_mongo_password

# url for the redis instance
redis_host: 172.17.0.1

# port for the redis instance
redis_port: 6379

# password required for redis
#redis_password: the_redis_password


[rabbit]
# url and port for the rabbitmq instance
uri: amqp://172.17.0.1:5672


[spawner]
# For scalability, worker containers can run on separate physical hosts. At least one
# spawner and one health check worker should be launched on each worker host, and the
# host_id should be the unique for each worker host.
host_id: 0

# An addressable IP for the spawner's host. This config is not currently used but could
# be at a future date to support a conatiner scheduler like swarm or mesos.
host_ip: 172.17.0.1

# When new workers are spawned, a config file must be mounted for communication with rabbit and redis.
# This path should be an absolute path *on the host* where such a config file exists. By default, spawners
# read this path from an environment variable, abaco_conf_host_path, but if this variable isn't set spawners
# will fall back to using this configuration.
# abaco_conf_host_path: /path/to/abaco.conf

# the maximum number of workers that are allowed to simultaneously be running on a given compute host.
# Spawners will unsubscribe from the command channel when this threshold is met.
# For local development, we intentially keep the max workers small:
max_workers_per_host: 40

# the default maximum number of workers that a given actor can have at one time. admin's can set the
# max_workers attribute for a given actor to a different number. the autoscaler will not scale
# an actor's worker pool beyond this number.
max_workers_per_actor: 15


[docker]
# url to use for docker daemon by spawners and workers. Currently only the unix socket is
# supported but other options could be implemented in the future.
dd: unix://var/run/docker.sock


[workers]
# number of worker containers to initially start when an actor is created
init_count: 1

# max length of time, in seconds, an actor container is allowed to execute before being killed.
# set to -1 for indefinite execution time.
max_run_time: -1

# The maximum amount of memory an Actor container can use; similar to the --memory flag in Docker
# set to -1 for unlimited memory
# examples:
# limit each actor to 1 gig
# mem_limit = 1g
# limit each actor to 5 meg
# mem_limit = 5m

# maximum number of CPUs each actor will have available to them. Does not guarantee these CPU resources
# to each actor, but rather provides the upper bound on available resources.
# set to -1 for unlimited CPU resources.
# allow access to 1 cpu
max_cpus = 1000000000


# length of time, in seconds, to keep an idle worker alive. Set to -1 to keep workers
# alive indefinitely.
# Set the ttl to 10 minutes. TODO
# worker_ttl: 600
# Set the ttl to 24 hours.
worker_ttl: 86400

# whether worker containers should be scheduled with the auto_remove flag. In general, this should be set to true
# but requires docker version > 1.25 so should be set to false when that is not the case. Also can be helpful to set to
# False for development/debugging efforts.
auto_remove: false

# Whether the workers should have OAuth clients generated for them:
generate_clients: False

# a list of mounts to make for every actor container, separated by comma (,) characters.
# Mounts should be of the form <absolute_host_path>:<absolute_container_path>:<mode>
# where mode is either ro for read-only or rw for read-write.
# Token replacement done at runtime for the following:
# tenant_id: the tenant id associated with the actor.
# username: the username of the owner of the actor.
# tasdir: the homeDirectory attribute returned from tas. This attribute requires the
# use_tas_uid field to be set.
global_mounts: /data1:/_abaco_data1:ro,/data2/{tenant_id}/{username}:/_abaco_data2:rw
#, /data3/{tasdir}:/work:rw

# global mounts for a specific tenant; the format of the attribute is {tenant_id}_global mounts.
# Use lower case for the tenant_id.
# If this setting is in place, the general "global_mounts" config will be ignored for that tenant.
# Example of setting global mounts specifically for the designsafe tenant:
designsafe_global_mounts: /corral-repl/tacc/NHERI/shared/{username}:/mydata:rw
dev-develop_global_mounts: /data1:/_abaco_data1:ro

# a list of mounts to make for privileged actor containers. Follows the same format as the global mounts
privileged_mounts: /data1:/_abaco_data1:ro,/data2:/_abaco_data2:rw


# whether to leave the actor containers or remove them. Should be False in
# staging/production but setting True can be helpful when debugging locally.
leave_containers: False

# container uid and gid can be set on a tenant by tenant basis, or at a global level for the entire
# Abaco instance. By default, the container image's uid and gid will be used. through configuration,
# there are two other options: 1) using TAS (tacc accounting system) to run the container as the user's
# uid/gid, or 2) using a fixed uid/gid for all containers.

# to use a specific uid/gid for all containers within a tenant, set {tenant}_actor_uid and {tenant}_actor_gid;
# for example:
#dev-develop_actor_uid: 1000
#dev-develop_actor_gid: 1000

designsafe_actor_uid: 458981
designsafe_actor_gid: 816877

# to use a specific uid/gid for all containers, regardless of tenant, set actor_uid and actor_gid.
# for example:
# actor_uid: 1000
# actor_gid: 1000

# to run the actor containers as the UID associated with the owner of the actor in TAS.
# requires TAS_ROLE_ACCT and TAS_ROLE_PASS passes as environment variables.
# Default value is False in which case the container run as the UID set in the container image.
use_tas_uid: True

# to just use TAS uid/gid for a specific tenant, set {tenant}_use_tas_uid: True; for example, configure
# Abco to use TAS just for the sd2e tenant:
sd2e_use_tas_uid: True

# path on the workers host to use for mounting temporary socketes for processing execution results.
socket_host_path_dir: /_abaco_results_sockets

# path on the workers host to use for mounting temporary fifo's for processing binary messages.
fifo_host_path_dir: /_abaco_fifos


[web]
# type of access control for the web front end. supports: 'jwt', and 'none'
# access_control: none
access_control: jwt

# the role required for "base level" access to the service. This setting is only used when using JWT access control.
user_role: Internal/everyone

# whether to allow the use of nonces for authenticating requests to the API. The x-nonce query parameter is only
# checked in the absence of a JWT header.
accept_nonce: True

# the name of the tenant when not using jwt
tenant_name: dev_staging

# public key for the apim instance when deployed behind apim (jwt access control)
apim_public_key: MIGfMA0GCSqGSIb3DQEBAQUAA4GNADCBiQKBgQCUp/oV1vWc8/TkQSiAvTousMzOM4asB2iltr2QKozni5aVFu818MpOLZIr8LMnTzWllJvvaA5RAAdpbECb+48FjbBe0hseUdN5HpwvnH/DW8ZccGvk53I6Orq7hLCv1ZHtuOCokghz/ATrhyPq+QktMfXnRS4HrKGJTzxaCcU7OQIDAQAB

# whether the web apps return a stacktrace or a nice JSON object on an APIException:
# 'true' or 'false'
show_traceback: false

# Amount of time, in seconds, to store log data. Set to -1 to store indefinitely.
# Here we set the to 12 hours.
log_ex: 43200

# Either camel or snake: Whether to return responses in camel case or snake. Default is snake.
case: camel

# The maximum content length, in bytes, allowed for raw (binary) data messages.
# Below we set it to 500M:
max_content_length: 500000000